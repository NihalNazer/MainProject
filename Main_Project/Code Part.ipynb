{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83078a7d-7444-4237-9733-cfadcbe806ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect videos from a directory\n",
    "import os\n",
    "\n",
    "video_directory = 'C:/Users/nihal/Desktop/Academics/Main/MainProject/Main_Project/Data Video'\n",
    "videos = []\n",
    "for filename in os.listdir(video_directory):\n",
    "    if filename.endswith('.mp4'):\n",
    "        videos.append(os.path.join(video_directory, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5458bfe-e41c-47aa-9523-e5c12346282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize videos to a standard size\n",
    "import cv2\n",
    "\n",
    "width, height = 640, 360\n",
    "\n",
    "for video in videos:\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (width, height))\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    # Save resized frames to disk\n",
    "    video_name = os.path.splitext(os.path.basename(video))[0]\n",
    "    for i, frame in enumerate(frames):\n",
    "        filename = f'{video_name}_frame{i:03}.jpg'\n",
    "        cv2.imwrite(os.path.join('C:/Users/nihal/Desktop/Academics/Main/MainProject/Main_Project/Data Video/frame', filename), frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92ff346e-ebeb-4c1f-81f9-f8e2d60a7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edge features from video frames\n",
    "import numpy as np\n",
    "\n",
    "def extract_edges(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    return np.dstack((edges, edges, edges))\n",
    "\n",
    "features = []\n",
    "\n",
    "num_frames = 16  # Set the number of frames per video\n",
    "\n",
    "for video in videos:\n",
    "    video_name = os.path.splitext(os.path.basename(video))[0]\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames_per_segment = frame_count // num_frames\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        frame_number = i * frames_per_segment\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "            edges = extract_edges(frame)\n",
    "            features.append(edges)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f06274e-20c4-4b51-a59d-18938603a9b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_4\" is incompatible with the layer: expected ndim=3, found ndim=5. Full shape received: (None, 16, 104, 104, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26532\\485580578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Define the LSTM layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mlstm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mlstm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[1;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[1;34m\"is incompatible with the layer: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"lstm_4\" is incompatible with the layer: expected ndim=3, found ndim=5. Full shape received: (None, 16, 104, 104, 256)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, TimeDistributed, Flatten, Permute, Reshape, Multiply, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 32\n",
    "num_frames = 10\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "\n",
    "input_tensor = Input(shape=(num_frames, height, width, channels))\n",
    "\n",
    "# Reshape the input tensor\n",
    "reshaped_input = Reshape((num_frames, -1))(input_tensor)\n",
    "\n",
    "# Define the LSTM layer\n",
    "lstm_layer = LSTM(128, return_sequences=True)(reshaped_input)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(num_classes, activation='softmax')(lstm_layer)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_tensor, outputs=output_layer)\n",
    "\n",
    "# Define the convolutional layers\n",
    "conv1 = TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu'))(inputs)\n",
    "conv2 = TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu'))(conv1)\n",
    "conv3 = TimeDistributed(Conv2D(128, kernel_size=(3, 3), activation='relu'))(conv2)\n",
    "conv4 = TimeDistributed(Conv2D(256, kernel_size=(3, 3), activation='relu'))(conv3)\n",
    "\n",
    "# Assuming your current input tensor shape is (batch_size, num_frames, height, width, channels)\n",
    "reshaped_input = Reshape((num_frames, -1))(input_tensor)\n",
    "\n",
    "# Define the LSTM layer\n",
    "lstm1 = LSTM(256, return_sequences=True)(conv4)\n",
    "lstm2 = LSTM(256)(lstm1)\n",
    "\n",
    "# Define the attention mechanism\n",
    "permute = Permute((2, 1))(lstm1)\n",
    "reshape = Reshape((-1, 256))(permute)\n",
    "dense1 = Dense(attention_size, activation='tanh')(reshape)\n",
    "dropout1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(1, activation='linear')(dropout1)\n",
    "flatten = Flatten()(dense2)\n",
    "softmax = Lambda(lambda x: K.softmax(x, axis=1))(flatten)\n",
    "reshape2 = Reshape((-1, 1))(softmax)\n",
    "attention = Multiply()([lstm1, reshape2])\n",
    "attention_sum = Lambda(lambda x: K.sum(x, axis=1))(attention)\n",
    "\n",
    "# Define the fully connected layers\n",
    "flatten2 = Flatten()(attention_sum)\n",
    "dense3 = Dense(128, activation='relu')(flatten2)\n",
    "dropout2 = Dropout(0.5)(dense3)\n",
    "dense4 = Dense(64, activation='relu')(dropout2)\n",
    "dropout3 = Dropout(0.5)(dense4)\n",
    "\n",
    "# Define the output layer\n",
    "output = Dense(num_classes, activation='softmax')(dropout3)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Load the video data\n",
    "data_dir = 'C:/Users/nihal/Desktop/project'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "train_videos = [os.path.join(train_dir, f) for f in os.listdir(train_dir)]\n",
    "val_videos = [os.path.join(val_dir, f) for f in os.listdir(val_dir)]\n",
    "test_videos = [os.path.join(test_dir, f) for f in os.listdir(test_dir)]\n",
    "\n",
    "# Define the function to extract frames from a video\n",
    "def extract_frames(video):\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames_per_segment = frame_count // num_frames\n",
    "    frames = []\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        frame_number = i * frames_per_segment\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (width, height))\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    frames = np.array(frames)\n",
    "    return frames\n",
    "\n",
    "# Define the function to load the data\n",
    "def load_data(videos):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for video in videos:\n",
    "        frames = extract_frames(video)\n",
    "        label = os.path.basename(os.path.dirname(video))\n",
    "        X.append(frames)\n",
    "        y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load the training, validation, and testing data\n",
    "X_train, y_train = load_data(train_videos)\n",
    "X_val, y_val = load_data(val_videos)\n",
    "X_test, y_test = load_data(test_videos)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "y_train_one_hot = one_hot_encoder.fit_transform(y_train_encoded.reshape(-1, 1))\n",
    "y_val_one_hot = one_hot_encoder.transform(y_val_encoded.reshape(-1, 1))\n",
    "y_test_one_hot = one_hot_encoder.transform(y_test_encoded.reshape(-1, 1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_one_hot, batch_size=32, epochs=10, validation_data=(X_val, y_val_one_hot))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test_one_hot)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f5a98-ba96-4b0e-aa74-d0010c02caf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
